{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vanaja146/Backend/blob/main/MiniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Title: Audio To Text**"
      ],
      "metadata": {
        "id": "CDBc3YWvHoxL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "0F59SEQC_1lx",
        "outputId": "0f9d43bc-b103-4fdb-9a0a-300cb76ceb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: SpeechRecognition, pyngrok\n",
            "Successfully installed SpeechRecognition-3.14.3 pyngrok-7.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <h2>Real-time Voice-to-Text Detection App is running!</h2>\n",
              "        <p>Access your app at this URL: <a href=\"https://8c9b87e3f134.ngrok-free.app\" target=\"_blank\">https://8c9b87e3f134.ngrok-free.app</a></p>\n",
              "        <p>Important: Be sure to allow microphone access in your browser when prompted!</p>\n",
              "        <p>Instructions:</p>\n",
              "        <ol>\n",
              "            <li>Click \"Start Recording\" and begin speaking</li>\n",
              "            <li>The app will automatically process your speech in real-time (every 5 seconds)</li>\n",
              "            <li>Click \"Stop Recording\" when you're done</li>\n",
              "            <li>View your transcription history below the current transcription</li>\n",
              "        </ol>\n",
              "        <p><strong>Note:</strong> If you still encounter issues, make sure pop-ups aren't blocked and try using Chrome browser.</p>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Voice-to-Text App with Ngrok Fix for Google Colab\n",
        "# Install required packages\n",
        "!pip install SpeechRecognition flask pydub pyngrok\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "import flask\n",
        "from flask import Flask, request, render_template_string, jsonify\n",
        "from pyngrok import ngrok\n",
        "import base64\n",
        "import io\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "import IPython.display as ipd\n",
        "from IPython.display import HTML, display\n",
        "import threading\n",
        "import time\n",
        "import queue\n",
        "\n",
        "# Create a Flask app for the web interface\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Queue for processing audio recordings\n",
        "audio_queue = queue.Queue()\n",
        "results = {}\n",
        "\n",
        "# Function to process audio in the background\n",
        "def process_audio_files():\n",
        "    while True:\n",
        "        try:\n",
        "            file_id, audio_path = audio_queue.get(timeout=1)\n",
        "            try:\n",
        "                with sr.AudioFile(audio_path) as source:\n",
        "                    audio_data = recognizer.record(source)\n",
        "                    # Using Google's Speech Recognition\n",
        "                    text = recognizer.recognize_google(audio_data)\n",
        "                    results[file_id] = {\"status\": \"complete\", \"text\": text}\n",
        "            except Exception as e:\n",
        "                results[file_id] = {\"status\": \"error\", \"error\": str(e)}\n",
        "            finally:\n",
        "                # Clean up temp file\n",
        "                if os.path.exists(audio_path):\n",
        "                    os.remove(audio_path)\n",
        "                audio_queue.task_done()\n",
        "        except queue.Empty:\n",
        "            time.sleep(0.1)\n",
        "\n",
        "# Start the background thread\n",
        "process_thread = threading.Thread(target=process_audio_files, daemon=True)\n",
        "process_thread.start()\n",
        "\n",
        "# HTML template for the web interface\n",
        "HTML_TEMPLATE = '''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Voice to Text Converter</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 20px;\n",
        "            background-color: #f5f5f5;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "            background-color: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        h1 {\n",
        "            color: #333;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .section {\n",
        "            margin-bottom: 20px;\n",
        "            padding: 15px;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 4px;\n",
        "        }\n",
        "        .section h2 {\n",
        "            margin-top: 0;\n",
        "            color: #444;\n",
        "        }\n",
        "        button {\n",
        "            padding: 12px 20px;\n",
        "            background-color: #4285f4;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 4px;\n",
        "            cursor: pointer;\n",
        "            margin: 5px 0;\n",
        "            font-size: 16px;\n",
        "            transition: all 0.3s ease;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #3367d6;\n",
        "            transform: translateY(-2px);\n",
        "            box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        button:disabled {\n",
        "            background-color: #cccccc;\n",
        "            cursor: not-allowed;\n",
        "            transform: none;\n",
        "            box-shadow: none;\n",
        "        }\n",
        "        #result {\n",
        "            margin-top: 20px;\n",
        "            padding: 15px;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 4px;\n",
        "            min-height: 100px;\n",
        "            background-color: #fafafa;\n",
        "        }\n",
        "        .loader {\n",
        "            border: 5px solid #f3f3f3;\n",
        "            border-top: 5px solid #3498db;\n",
        "            border-radius: 50%;\n",
        "            width: 30px;\n",
        "            height: 30px;\n",
        "            animation: spin 2s linear infinite;\n",
        "            margin: 10px auto;\n",
        "            display: none;\n",
        "        }\n",
        "        @keyframes spin {\n",
        "            0% { transform: rotate(0deg); }\n",
        "            100% { transform: rotate(360deg); }\n",
        "        }\n",
        "        #audioControls {\n",
        "            display: flex;\n",
        "            justify-content: space-around;\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "        .record-btn {\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            width: 180px;\n",
        "            height: 60px;\n",
        "            border-radius: 30px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        #recordBtn {\n",
        "            background-color: #ea4335;\n",
        "        }\n",
        "        #recordBtn:hover {\n",
        "            background-color: #d62516;\n",
        "        }\n",
        "        #stopBtn {\n",
        "            background-color: #34a853;\n",
        "        }\n",
        "        #stopBtn:hover {\n",
        "            background-color: #2d9249;\n",
        "        }\n",
        "        .status-indicator {\n",
        "            text-align: center;\n",
        "            font-weight: bold;\n",
        "            margin: 10px 0;\n",
        "            color: #555;\n",
        "        }\n",
        "        .recording-pulse {\n",
        "            display: inline-block;\n",
        "            width: 18px;\n",
        "            height: 18px;\n",
        "            border-radius: 50%;\n",
        "            background: #ea4335;\n",
        "            margin-right: 10px;\n",
        "            animation: pulse 1.5s infinite;\n",
        "        }\n",
        "        @keyframes pulse {\n",
        "            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); }\n",
        "            70% { transform: scale(1); box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); }\n",
        "            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(234, 67, 53, 0); }\n",
        "        }\n",
        "        .transcript-history {\n",
        "            max-height: 300px;\n",
        "            overflow-y: auto;\n",
        "            border: 1px solid #eee;\n",
        "            padding: 10px;\n",
        "            border-radius: 4px;\n",
        "            background-color: white;\n",
        "            margin-top: 15px;\n",
        "        }\n",
        "        .transcript-entry {\n",
        "            padding: 8px;\n",
        "            border-bottom: 1px solid #eee;\n",
        "        }\n",
        "        .transcript-entry:last-child {\n",
        "            border-bottom: none;\n",
        "        }\n",
        "        .transcript-time {\n",
        "            font-size: 12px;\n",
        "            color: #777;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>Real-time Voice to Text Converter</h1>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>Voice Detection</h2>\n",
        "            <p>Click \"Start Recording\" and speak into your microphone to convert your voice to text in real-time.</p>\n",
        "\n",
        "            <div id=\"audioControls\">\n",
        "                <button id=\"recordBtn\" class=\"record-btn\">\n",
        "                    <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"white\">\n",
        "                        <path d=\"M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z\"/>\n",
        "                        <path d=\"M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z\"/>\n",
        "                    </svg>\n",
        "                    &nbsp;Start Recording\n",
        "                </button>\n",
        "                <button id=\"stopBtn\" class=\"record-btn\" disabled>\n",
        "                    <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"white\">\n",
        "                        <path d=\"M6 6h12v12H6z\"/>\n",
        "                    </svg>\n",
        "                    &nbsp;Stop Recording\n",
        "                </button>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"status-indicator\" id=\"recordingStatus\" style=\"display: none;\">\n",
        "                <span class=\"recording-pulse\"></span> Recording in progress...\n",
        "            </div>\n",
        "\n",
        "            <div class=\"loader\" id=\"recordLoader\"></div>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"result\">\n",
        "            <h2>Current Transcription</h2>\n",
        "            <p id=\"transcription\">No transcription available yet. Click \"Start Recording\" and speak into your microphone.</p>\n",
        "\n",
        "            <h3>Transcript History</h3>\n",
        "            <div class=\"transcript-history\" id=\"transcriptHistory\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        // Recording functionality\n",
        "        let mediaRecorder;\n",
        "        let audioChunks = [];\n",
        "        let transcriptHistory = [];\n",
        "        let isRecording = false;\n",
        "        let continuousRecording = false;\n",
        "        let recordingInterval;\n",
        "\n",
        "        document.getElementById('recordBtn').addEventListener('click', startRecording);\n",
        "        document.getElementById('stopBtn').addEventListener('click', stopRecording);\n",
        "\n",
        "        async function startRecording() {\n",
        "            try {\n",
        "                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "                mediaRecorder = new MediaRecorder(stream);\n",
        "\n",
        "                audioChunks = [];\n",
        "                mediaRecorder.ondataavailable = function(e) {\n",
        "                    audioChunks.push(e.data);\n",
        "                };\n",
        "\n",
        "                mediaRecorder.onstop = processRecording;\n",
        "\n",
        "                // Start recording\n",
        "                mediaRecorder.start();\n",
        "                isRecording = true;\n",
        "\n",
        "                // Enable continuous recording mode\n",
        "                continuousRecording = true;\n",
        "\n",
        "                // Update UI\n",
        "                document.getElementById('recordBtn').disabled = true;\n",
        "                document.getElementById('stopBtn').disabled = false;\n",
        "                document.getElementById('recordingStatus').style.display = 'block';\n",
        "                document.getElementById('transcription').textContent = 'Listening...';\n",
        "\n",
        "                // Set up continuous recording (stop and restart every 5 seconds to get real-time transcription)\n",
        "                recordingInterval = setInterval(() => {\n",
        "                    if (isRecording && continuousRecording) {\n",
        "                        mediaRecorder.stop();\n",
        "                        // Will restart in the onstop handler\n",
        "                    }\n",
        "                }, 5000); // Process every 5 seconds\n",
        "            } catch (error) {\n",
        "                console.error('Error accessing microphone:', error);\n",
        "                alert('Error accessing microphone. Please make sure you have granted microphone permissions: ' + error);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function stopRecording() {\n",
        "            // Stop continuous recording\n",
        "            continuousRecording = false;\n",
        "            clearInterval(recordingInterval);\n",
        "\n",
        "            // Stop current recording if active\n",
        "            if (mediaRecorder && mediaRecorder.state !== 'inactive') {\n",
        "                mediaRecorder.stop();\n",
        "            }\n",
        "\n",
        "            // Update UI\n",
        "            isRecording = false;\n",
        "            document.getElementById('recordBtn').disabled = false;\n",
        "            document.getElementById('stopBtn').disabled = true;\n",
        "            document.getElementById('recordingStatus').style.display = 'none';\n",
        "        }\n",
        "\n",
        "        function processRecording() {\n",
        "            if (audioChunks.length === 0) {\n",
        "                // No audio data to process\n",
        "                if (continuousRecording && isRecording) {\n",
        "                    // Restart recording for continuous mode\n",
        "                    mediaRecorder.start();\n",
        "                }\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n",
        "            audioChunks = []; // Clear for next recording\n",
        "\n",
        "            const formData = new FormData();\n",
        "            formData.append('file', audioBlob, 'recording.wav');\n",
        "\n",
        "            document.getElementById('recordLoader').style.display = 'block';\n",
        "\n",
        "            fetch('/upload', {\n",
        "                method: 'POST',\n",
        "                body: formData\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                if (data.file_id) {\n",
        "                    checkStatus(data.file_id);\n",
        "                } else {\n",
        "                    throw new Error('No file ID returned');\n",
        "                }\n",
        "\n",
        "                // Restart recording if in continuous mode\n",
        "                if (continuousRecording && isRecording) {\n",
        "                    mediaRecorder.start();\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                console.error('Error processing recording:', error);\n",
        "                document.getElementById('recordLoader').style.display = 'none';\n",
        "\n",
        "                // Still restart recording if in continuous mode, despite error\n",
        "                if (continuousRecording && isRecording) {\n",
        "                    mediaRecorder.start();\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Check the status of processing\n",
        "        function checkStatus(fileId) {\n",
        "            fetch(`/status/${fileId}`)\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                if (data.status === 'complete') {\n",
        "                    document.getElementById('recordLoader').style.display = 'none';\n",
        "                    document.getElementById('transcription').textContent = data.text;\n",
        "\n",
        "                    // Add to transcript history\n",
        "                    addToTranscriptHistory(data.text);\n",
        "                } else if (data.status === 'error') {\n",
        "                    document.getElementById('recordLoader').style.display = 'none';\n",
        "                    if (data.error.includes(\"Could not understand audio\")) {\n",
        "                        document.getElementById('transcription').textContent = \"Didn't catch that. Please try speaking again.\";\n",
        "                    } else {\n",
        "                        document.getElementById('transcription').textContent = 'Error: ' + data.error;\n",
        "                    }\n",
        "                } else {\n",
        "                    // Still processing, check again in 1 second\n",
        "                    setTimeout(() => checkStatus(fileId), 1000);\n",
        "                }\n",
        "            })\n",
        "            .catch(error => {\n",
        "                console.error('Error checking status:', error);\n",
        "                document.getElementById('recordLoader').style.display = 'none';\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Add transcription to history\n",
        "        function addToTranscriptHistory(text) {\n",
        "            if (!text || text.trim() === '') return;\n",
        "\n",
        "            const now = new Date();\n",
        "            const timestamp = now.toLocaleTimeString();\n",
        "\n",
        "            transcriptHistory.unshift({\n",
        "                text: text,\n",
        "                timestamp: timestamp\n",
        "            });\n",
        "\n",
        "            // Keep only last 10 entries\n",
        "            if (transcriptHistory.length > 10) {\n",
        "                transcriptHistory = transcriptHistory.slice(0, 10);\n",
        "            }\n",
        "\n",
        "            // Update the UI\n",
        "            updateTranscriptHistory();\n",
        "        }\n",
        "\n",
        "        // Update transcript history display\n",
        "        function updateTranscriptHistory() {\n",
        "            const historyContainer = document.getElementById('transcriptHistory');\n",
        "            historyContainer.innerHTML = '';\n",
        "\n",
        "            transcriptHistory.forEach(entry => {\n",
        "                const entryElement = document.createElement('div');\n",
        "                entryElement.className = 'transcript-entry';\n",
        "\n",
        "                const textElement = document.createElement('div');\n",
        "                textElement.textContent = entry.text;\n",
        "\n",
        "                const timeElement = document.createElement('div');\n",
        "                timeElement.className = 'transcript-time';\n",
        "                timeElement.textContent = entry.timestamp;\n",
        "\n",
        "                entryElement.appendChild(textElement);\n",
        "                entryElement.appendChild(timeElement);\n",
        "                historyContainer.appendChild(entryElement);\n",
        "            });\n",
        "\n",
        "            if (transcriptHistory.length === 0) {\n",
        "                historyContainer.innerHTML = '<p>No transcriptions yet.</p>';\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No file part'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    # Generate a unique file ID\n",
        "    file_id = str(time.time())\n",
        "\n",
        "    # Save to a temporary file\n",
        "    temp_dir = tempfile.gettempdir()\n",
        "    file_path = os.path.join(temp_dir, f\"{file_id}.wav\")\n",
        "\n",
        "    # Convert any audio format to WAV for compatibility with SpeechRecognition\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file)\n",
        "        audio.export(file_path, format=\"wav\")\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': f'Error processing audio: {str(e)}'}), 400\n",
        "\n",
        "    # Add to the processing queue\n",
        "    audio_queue.put((file_id, file_path))\n",
        "    results[file_id] = {\"status\": \"processing\"}\n",
        "\n",
        "    return jsonify({'file_id': file_id})\n",
        "\n",
        "@app.route('/status/<file_id>')\n",
        "def check_status(file_id):\n",
        "    if file_id not in results:\n",
        "        return jsonify({'status': 'not_found'})\n",
        "    return jsonify(results[file_id])\n",
        "\n",
        "# Run the app with ngrok (to avoid 403 Forbidden errors)\n",
        "def run_app_with_ngrok():\n",
        "    # Set your authtoken here (required)\n",
        "    ngrok.set_auth_token(\"2tz1MPC8Ih9qeufiRx4uyeq8Mii_2Q9DWJ7HysQ3TcctFfdrA\")\n",
        "\n",
        "    # Set up ngrok tunnel\n",
        "    ngrok_tunnel = ngrok.connect(5000)\n",
        "    public_url = ngrok_tunnel.public_url\n",
        "\n",
        "    # Start the Flask server in a thread\n",
        "    threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)).start()\n",
        "\n",
        "    # Display the access information\n",
        "    display(HTML(f'''\n",
        "        <h2>Real-time Voice-to-Text Detection App is running!</h2>\n",
        "        <p>Access your app at this URL: <a href=\"{public_url}\" target=\"_blank\">{public_url}</a></p>\n",
        "        <p>Important: Be sure to allow microphone access in your browser when prompted!</p>\n",
        "        <p>Instructions:</p>\n",
        "        <ol>\n",
        "            <li>Click \"Start Recording\" and begin speaking</li>\n",
        "            <li>The app will automatically process your speech in real-time (every 5 seconds)</li>\n",
        "            <li>Click \"Stop Recording\" when you're done</li>\n",
        "            <li>View your transcription history below the current transcription</li>\n",
        "        </ol>\n",
        "        <p><strong>Note:</strong> If you still encounter issues, make sure pop-ups aren't blocked and try using Chrome browser.</p>\n",
        "    '''))\n",
        "\n",
        "# Execute in Colab\n",
        "if __name__ == '__main__':\n",
        "    run_app_with_ngrok()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j_asqlrwHmBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gBw8Ta_MHgq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g6T5k7e5HjVz"
      }
    }
  ]
}